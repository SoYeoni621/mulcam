{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoYeoni621/mulcam/blob/master/mini_preprocessing_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 빅카인즈 키워드 활용 전처리 함수들"
      ],
      "metadata": {
        "id": "3fS3wwdUUA29"
      },
      "id": "3fS3wwdUUA29"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf606d8b",
      "metadata": {
        "id": "cf606d8b"
      },
      "outputs": [],
      "source": [
        "# 키워드 추출(단순 빈도수)\n",
        "\n",
        "def ExtractKeyword(df, year, month):\n",
        "    terms = (df['year'] == year) & (df['month'] == month)\n",
        "    ans = df[terms]\n",
        "    ans.reset_index(inplace=True)\n",
        "    \n",
        "    WordList = []\n",
        "    for i in range(len(ans['키워드'])): \n",
        "        words = ans['키워드'][i].split(',')\n",
        "        \n",
        "        for j in range(len(words)):\n",
        "            word = words[j]\n",
        "            WordList.append(word)\n",
        "            \n",
        "    word_counter = Counter(WordList)\n",
        "    result = word_counter.most_common(30)\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8fcb558",
      "metadata": {
        "id": "a8fcb558"
      },
      "outputs": [],
      "source": [
        "# 불용어 제외(겹치는 단어는 제외하는 방식)\n",
        "def ExtractKey(df, year, month, stopwords):\n",
        "    terms = (df['year'] == year) & (df['month'] == month)\n",
        "    ans = df[terms]\n",
        "    ans.reset_index(inplace=True)\n",
        "    \n",
        "    WordList = []\n",
        "    stopwords = stopwords\n",
        "    for i in range(len(ans['키워드'])): \n",
        "        words = ans['키워드'][i].split(',')\n",
        "        \n",
        "        for j in range(len(words)):\n",
        "            word = words[j]\n",
        "            if not word in stopwords:\n",
        "                WordList.append(word)\n",
        "            \n",
        "    word_counter = Counter(WordList)\n",
        "    result = word_counter.most_common(5)\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7321f22",
      "metadata": {
        "id": "a7321f22"
      },
      "outputs": [],
      "source": [
        "# 빈 데이터프레임 생성 후 채우는 함수\n",
        "\n",
        "def FillDataFrame(df1, df2, year, month, stopwords):\n",
        "    result = ExtractKey(df1, year, month, stopwords)\n",
        "    df2.loc[(df2['연도'] == year) & (df2['월'] == month), '키워드1'] = result[0][0]\n",
        "    df2.loc[(df2['연도'] == year) & (df2['월'] == month), '빈도수1'] = result[0][1]\n",
        "    df2.loc[(df2['연도'] == year) & (df2['월'] == month), '키워드2'] = result[1][0]\n",
        "    df2.loc[(df2['연도'] == year) & (df2['월'] == month), '빈도수2'] = result[1][1]\n",
        "    df2.loc[(df2['연도'] == year) & (df2['월'] == month), '키워드3'] = result[2][0]\n",
        "    df2.loc[(df2['연도'] == year) & (df2['월'] == month), '빈도수3'] = result[2][1]\n",
        "    df2.loc[(df2['연도'] == year) & (df2['월'] == month), '키워드4'] = result[3][0]\n",
        "    df2.loc[(df2['연도'] == year) & (df2['월'] == month), '빈도수4'] = result[3][1]\n",
        "    df2.loc[(df2['연도'] == year) & (df2['월'] == month), '키워드5'] = result[4][0]\n",
        "    df2.loc[(df2['연도'] == year) & (df2['월'] == month), '빈도수5'] = result[4][1]\n",
        "    \n",
        "    return df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a254bb3",
      "metadata": {
        "id": "1a254bb3"
      },
      "outputs": [],
      "source": [
        "# top3 키워드를 모두 포함하는 기사 URL 추출\n",
        "# df1=뉴스데이터, df2=키워드데이터, com=기업명\n",
        "def ExtractURL(df1, df2, year, month, com=None):\n",
        "    ndf1 = df1.loc[(df1['연도'] == year) & (df1['월'] == month)]\n",
        "    ndf2 = df2.loc[(df2['연도'] == year) & (df2['월'] == month)]\n",
        "    ndf2.reset_index(inplace=True)\n",
        "    \n",
        "    a = ndf2['키워드1'][0]\n",
        "    b = ndf2['키워드2'][0]\n",
        "    c = ndf2['키워드3'][0]\n",
        "    \n",
        "    temp = ndf1.loc[(ndf1['키워드'].str.contains(a)) & (ndf1['키워드'].str.contains(b)) & (ndf1['키워드'].str.contains(c))]\n",
        "    temp.reset_index(inplace=True)\n",
        "    \n",
        "    columns = ['기업명', '연도', '월', '언론사', '제목', 'URL']\n",
        "    new_df = pd.DataFrame(index=range(0, len(temp)), columns=columns)\n",
        "    new_df['기업명'] = com\n",
        "    new_df['연도'] = year\n",
        "    new_df['월'] = month\n",
        "    new_df['언론사'] = temp['언론사']\n",
        "    new_df['제목'] = temp['제목']\n",
        "    new_df['URL'] = temp['URL']\n",
        "    \n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52294380",
      "metadata": {
        "id": "52294380"
      },
      "outputs": [],
      "source": [
        "def url_concat(df1,df2, com=None):\n",
        "    irl_2018=pd.concat([ExtractURL(df1, df2, 2018,1, com=com),ExtractURL(df1, df2, 2018,2, com=com),ExtractURL(df1, df2, 2018,3, com=com),ExtractURL(df1, df2, 2018,4, com=com),ExtractURL(df1, df2, 2018,5, com=com),ExtractURL(df1, df2, 2018,6, com=com),ExtractURL(df1, df2, 2018,7, com=com),ExtractURL(df1, df2, 2018,8, com=com),ExtractURL(df1, df2, 2018,9, com=com),ExtractURL(df1, df2, 2018,10, com=com),ExtractURL(df1, df2, 2018,11, com=com),ExtractURL(df1, df2, 2018,12, com=com)])\n",
        "    irl_2019=pd.concat([ExtractURL(df1, df2, 2019,1, com=com),ExtractURL(df1, df2, 2019,2, com=com),ExtractURL(df1, df2, 2019,3, com=com),ExtractURL(df1, df2, 2019,4, com=com),ExtractURL(df1, df2, 2019,5, com=com),ExtractURL(df1, df2, 2019,6, com=com),ExtractURL(df1, df2, 2019,7, com=com),ExtractURL(df1, df2, 2019,8, com=com),ExtractURL(df1, df2, 2019,9, com=com),ExtractURL(df1, df2, 2019,10, com=com),ExtractURL(df1, df2, 2019,11, com=com),ExtractURL(df1, df2, 2019,12, com=com)])\n",
        "    irl_2020=pd.concat([ExtractURL(df1, df2, 2020,1, com=com),ExtractURL(df1, df2, 2020,2, com=com),ExtractURL(df1, df2, 2020,3, com=com),ExtractURL(df1, df2, 2020,4, com=com),ExtractURL(df1, df2, 2020,5, com=com),ExtractURL(df1, df2, 2020,6, com=com),ExtractURL(df1, df2, 2020,7, com=com),ExtractURL(df1, df2, 2020,8, com=com),ExtractURL(df1, df2, 2020,9, com=com),ExtractURL(df1, df2, 2020,10, com=com),ExtractURL(df1, df2, 2020,11, com=com),ExtractURL(df1, df2, 2020,12, com=com)])\n",
        "    irl_2021=pd.concat([ExtractURL(df1, df2, 2021,1, com=com),ExtractURL(df1, df2, 2021,2, com=com),ExtractURL(df1, df2, 2021,3, com=com),ExtractURL(df1, df2, 2021,4, com=com),ExtractURL(df1, df2, 2021,5, com=com),ExtractURL(df1, df2, 2021,6, com=com),ExtractURL(df1, df2, 2021,7, com=com),ExtractURL(df1, df2, 2021,8, com=com),ExtractURL(df1, df2, 2021,9, com=com),ExtractURL(df1, df2, 2021,10, com=com),ExtractURL(df1, df2, 2021,11, com=com),ExtractURL(df1, df2, 2021,12, com=com)])\n",
        "    irl_2022=pd.concat([ExtractURL(df1, df2, 2022,1, com=com),ExtractURL(df1, df2, 2022,2, com=com),ExtractURL(df1, df2, 2022,3, com=com)])\n",
        "    result = pd.concat([irl_2018,irl_2019,irl_2020,irl_2021,irl_2022],ignore_index=True)    \n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "285e0f10",
      "metadata": {
        "id": "285e0f10"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50de30ee",
      "metadata": {
        "id": "50de30ee"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c70d5a2",
      "metadata": {
        "id": "0c70d5a2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "177cc6b1",
      "metadata": {
        "id": "177cc6b1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81162253",
      "metadata": {
        "id": "81162253"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "mini_preprocessing_functions.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}