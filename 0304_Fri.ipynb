{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0304_Fri.ipynb",
      "provenance": [],
      "mount_file_id": "1OeZSdYfa35GZMIL3HT10uVrYgxfXudBo",
      "authorship_tag": "ABX9TyMoqXg4g40t9NMkrqiB/LGK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoYeoni621/mulcam/blob/master/0304_Fri.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RElRXwjpIxaR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((-1, 28, 28, 1))\n",
        "test_images = test_images.reshape((-1, 28, 28, 1))\n",
        "\n",
        "# normalization\n",
        "train_images = train_images/255.\n",
        "test_images = test_images/255.\n",
        "\n",
        "valid_images, test_images, valid_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.15, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "class ConvBNRelu(Model):\n",
        "    def __init__(self, filters, kernel_size=3, strides=(1,1), padding='same'):\n",
        "        super(ConvBNRelu, self).__init__()\n",
        "        self.conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
        "                           padding=padding, kernel_initializer='glorot_normal')\n",
        "        \n",
        "        self.batchnorm = BatchNormalization()\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        layer = self.conv(inputs)\n",
        "        layer = self.batchnorm(layer)\n",
        "        layer = tf.nn.relu(layer)\n",
        "\n",
        "        return layer\n",
        "        "
      ],
      "metadata": {
        "id": "ggzoTwuEKfew"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense에 Batchnorm 적용\n",
        "class DenseBNRelu(Model):\n",
        "    def __init__(self, units):\n",
        "        super(DenseBNRelu, self).__init__()\n",
        "        self.dense = Dense(units=units, kernel_initializer='glorot_normal')\n",
        "        self.batchnorm = BatchNormalization()\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        layer = self.dense(inputs)\n",
        "        layer = self.batchnorm(layer)\n",
        "        layer = tf.nn.relu(layer)\n",
        "\n",
        "        return layer\n"
      ],
      "metadata": {
        "id": "CQnwcB0ML4tX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTModel(Model):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.conv1 = ConvBNRelu(filters=32, kernel_size=(3, 3), padding='valid')\n",
        "        self.pool1 = MaxPool2D()\n",
        "        self.conv2 = ConvBNRelu(filters=64, kernel_size=(3, 3), padding='valid')\n",
        "        self.pool2 = MaxPool2D()\n",
        "        self.conv3 = ConvBNRelu(filters=64, kernel_size=(3, 3), padding='valid')\n",
        "        self.flat = Flatten()\n",
        "        self.dense4 = DenseBNRelu(units=64)\n",
        "        self.drop = Dropout(0.2)\n",
        "        self.outputs = Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        net = self.conv1(inputs)\n",
        "        net = self.pool1(net)\n",
        "        net = self.conv2(net)\n",
        "        net = self.pool2(net)\n",
        "        net = self.conv3(net)\n",
        "        net = self.flat(net)\n",
        "        net = self.dense4(net)\n",
        "        net = self.drop(net)\n",
        "        net = self.outputs(net)\n",
        "\n",
        "        return net"
      ],
      "metadata": {
        "id": "WoAyhmC0Ms8T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTModel()\n",
        "model(Input(shape=(28, 28, 1)))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nByi-C_dOl5b",
        "outputId": "27e51c51-111b-450b-c2f2-f76575a13f85"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mnist_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_bn_relu (ConvBNRelu)   multiple                  448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  multiple                 0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_bn_relu_1 (ConvBNRelu)  multiple                 18752     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv_bn_relu_2 (ConvBNRelu)  multiple                 37184     \n",
            "                                                                 \n",
            " flatten (Flatten)           multiple                  0         \n",
            "                                                                 \n",
            " dense_bn_relu (DenseBNRelu)  multiple                 37184     \n",
            "                                                                 \n",
            " dropout (Dropout)           multiple                  0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 94,218\n",
            "Trainable params: 93,770\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm '/content/drive/MyDrive/딥러닝 NLP/models'*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfTgvs1tQhKI",
        "outputId": "509607cf-d118-43dc-f86c-1b2bf0e5429d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/딥러닝 NLP/models': Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "MODEL_SAVE_FOLDER = '/content/drive/MyDrive/딥러닝 NLP/models/'\n",
        "model_path = f\"{MODEL_SAVE_FOLDER}mmist-{{epoch:d}}-{{val_loss:.5f}}-{{val_accuracy:.5f}}.hdf5\"\n",
        "\n",
        "cb_checkpoint = ModelCheckpoint(filepath=model_path, \n",
        "                                monitor='val_accuracy',\n",
        "                                save_weights_only=True,\n",
        "                                verbose=1,\n",
        "                                save_best_only=True)\n",
        "cb_early_stopping= EarlyStopping(monitor='val_accuracy',patience=6) # did not imporoved가 연속으로 6번 나오면 학습 stop"
      ],
      "metadata": {
        "id": "XrNuuEwfO-Kg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 200\n",
        "\n",
        "lr_decay = tf.keras.optimizers.schedules.ExponentialDecay(learning_rate, train_images.shape[0]/batch_size*5, 0.5, staircase=True)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_decay)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7W_HwJoDQoqF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(train_images, train_labels, validation_data=(valid_images, valid_labels),\n",
        "                 epochs=100, batch_size=batch_size, \n",
        "                 callbacks=[cb_checkpoint, cb_early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1LOLLSKRvAg",
        "outputId": "c4181021-fab4-48f1-a3ac-85e49453e667"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.2082 - accuracy: 0.9510\n",
            "Epoch 1: val_accuracy improved from -inf to 0.11294, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-1-4.40705-0.11294.hdf5\n",
            "300/300 [==============================] - 13s 26ms/step - loss: 0.2082 - accuracy: 0.9510 - val_loss: 4.4071 - val_accuracy: 0.1129\n",
            "Epoch 2/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0525 - accuracy: 0.9864\n",
            "Epoch 2: val_accuracy improved from 0.11294 to 0.98282, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-2-0.05850-0.98282.hdf5\n",
            "300/300 [==============================] - 6s 20ms/step - loss: 0.0523 - accuracy: 0.9864 - val_loss: 0.0585 - val_accuracy: 0.9828\n",
            "Epoch 3/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0356 - accuracy: 0.9898\n",
            "Epoch 3: val_accuracy did not improve from 0.98282\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 0.0356 - accuracy: 0.9899 - val_loss: 0.0649 - val_accuracy: 0.9793\n",
            "Epoch 4/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9926\n",
            "Epoch 4: val_accuracy improved from 0.98282 to 0.99106, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-4-0.02817-0.99106.hdf5\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 0.0270 - accuracy: 0.9926 - val_loss: 0.0282 - val_accuracy: 0.9911\n",
            "Epoch 5/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9940\n",
            "Epoch 5: val_accuracy did not improve from 0.99106\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.0280 - val_accuracy: 0.9904\n",
            "Epoch 6/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9970\n",
            "Epoch 6: val_accuracy improved from 0.99106 to 0.99118, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-6-0.02524-0.99118.hdf5\n",
            "300/300 [==============================] - 6s 20ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.0252 - val_accuracy: 0.9912\n",
            "Epoch 7/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9977\n",
            "Epoch 7: val_accuracy improved from 0.99118 to 0.99329, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-7-0.02285-0.99329.hdf5\n",
            "300/300 [==============================] - 6s 20ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.0229 - val_accuracy: 0.9933\n",
            "Epoch 8/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9980\n",
            "Epoch 8: val_accuracy did not improve from 0.99329\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.0227 - val_accuracy: 0.9927\n",
            "Epoch 9/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9982\n",
            "Epoch 9: val_accuracy did not improve from 0.99329\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.0276 - val_accuracy: 0.9919\n",
            "Epoch 10/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9986\n",
            "Epoch 10: val_accuracy did not improve from 0.99329\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0305 - val_accuracy: 0.9915\n",
            "Epoch 11/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9994\n",
            "Epoch 11: val_accuracy did not improve from 0.99329\n",
            "300/300 [==============================] - 6s 20ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0226 - val_accuracy: 0.9929\n",
            "Epoch 12/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995\n",
            "Epoch 12: val_accuracy did not improve from 0.99329\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0226 - val_accuracy: 0.9927\n",
            "Epoch 13/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9994\n",
            "Epoch 13: val_accuracy improved from 0.99329 to 0.99341, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-13-0.02251-0.99341.hdf5\n",
            "300/300 [==============================] - 6s 20ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0225 - val_accuracy: 0.9934\n",
            "Epoch 14/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9996\n",
            "Epoch 14: val_accuracy did not improve from 0.99341\n",
            "300/300 [==============================] - 6s 20ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0236 - val_accuracy: 0.9931\n",
            "Epoch 15/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9996\n",
            "Epoch 15: val_accuracy did not improve from 0.99341\n",
            "300/300 [==============================] - 6s 21ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0244 - val_accuracy: 0.9933\n",
            "Epoch 16/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 16: val_accuracy did not improve from 0.99341\n",
            "300/300 [==============================] - 6s 20ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0223 - val_accuracy: 0.9931\n",
            "Epoch 17/100\n",
            "299/300 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 17: val_accuracy did not improve from 0.99341\n",
            "300/300 [==============================] - 6s 20ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0220 - val_accuracy: 0.9929\n",
            "Epoch 18/100\n",
            "299/300 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9999\n",
            "Epoch 18: val_accuracy improved from 0.99341 to 0.99376, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-18-0.02067-0.99376.hdf5\n",
            "300/300 [==============================] - 6s 20ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0207 - val_accuracy: 0.9938\n",
            "Epoch 19/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9999\n",
            "Epoch 19: val_accuracy did not improve from 0.99376\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0238 - val_accuracy: 0.9933\n",
            "Epoch 20/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9999\n",
            "Epoch 20: val_accuracy did not improve from 0.99376\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0235 - val_accuracy: 0.9933\n",
            "Epoch 21/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999\n",
            "Epoch 21: val_accuracy did not improve from 0.99376\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0223 - val_accuracy: 0.9934\n",
            "Epoch 22/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9999\n",
            "Epoch 22: val_accuracy did not improve from 0.99376\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0227 - val_accuracy: 0.9934\n",
            "Epoch 23/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 9.3057e-04 - accuracy: 0.9999\n",
            "Epoch 23: val_accuracy did not improve from 0.99376\n",
            "300/300 [==============================] - 6s 19ms/step - loss: 9.3219e-04 - accuracy: 0.9999 - val_loss: 0.0232 - val_accuracy: 0.9933\n",
            "Epoch 24/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 8.1792e-04 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.99376\n",
            "300/300 [==============================] - 6s 20ms/step - loss: 8.1695e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train_loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='valid_loss')\n",
        "loss_ax.set_xlabel('epochs')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='train_accuracy')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label='valid_accuracy')\n",
        "acc_ax.set_xlabel('epochs')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.legend(loc='upper right', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "DJTax8X0SRrp",
        "outputId": "9c908bc0-57ab-4157-a7b2-a7c567cd90ea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG16 실습(사전 학습 모델pre-trained model)"
      ],
      "metadata": {
        "id": "p2H3SAt8egqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "yp2Z3Xt3Tw0b"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "print(train_images.shape, test_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRbqc9UpsZHL",
        "outputId": "1ab34132-61ed-4c5f-dddc-3998a85959ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 채널로 만들기 위한 작업\n",
        "train_images = train_images.reshape(-1, 784)\n",
        "test_images = test_images.reshape(-1, 784)\n",
        "\n",
        "print(train_images.shape, test_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mOGdQnEa1pJ",
        "outputId": "dcb8b72a-5162-47d5-8129-84ec98ef444c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784) (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 채널로 만들기\n",
        "train_images = np.dstack([train_images]*3)\n",
        "test_images = np.dstack([test_images]*3)"
      ],
      "metadata": {
        "id": "WjKk3v-0bHjy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape, test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2TgczLobOxK",
        "outputId": "4e34ddad-1bc4-47c4-f487-c08e8afa76f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784, 3), (10000, 784, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 형식으로 변경\n",
        "train_images = train_images.reshape(-1, 28, 28, 3)\n",
        "test_images = test_images.reshape(-1, 28, 28, 3)\n"
      ],
      "metadata": {
        "id": "LnBGJECRb1Jm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape, test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ99biFrcRs1",
        "outputId": "ec574d18-4141-447e-d1cc-44ab751eec97"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 3), (10000, 28, 28, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sT1PBQTc37q",
        "outputId": "e276d89b-2fcb-4b02-82e1-2874d04e1712"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0],\n",
              "       [0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "\n",
        "#48*48 사이즈로 변경\n",
        "\n",
        "train_images = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48, 48))) for im in train_images])\n",
        "test_images = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48, 48))) for im in test_images])"
      ],
      "metadata": {
        "id": "yLzqBNAHcTUp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape,  test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZwzm1Hvdsfs",
        "outputId": "ba96df12-e7f5-4382-fa0a-5c6903388bb7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 48, 48, 3), (10000, 48, 48, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images/ 255.\n",
        "test_images = test_images / 255.\n"
      ],
      "metadata": {
        "id": "CbsfDsCRs8cH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_images, test_images, valid_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.15, shuffle=True)"
      ],
      "metadata": {
        "id": "i97sUDZBs_PZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사전 학습된 VGG모델 가져오기\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
        "vgg_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD4Oea_jg5km",
        "outputId": "73067396-6d4d-4962-b379-6a7a1a7f9099"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 레이어 데이터화\n",
        "layer_dict = {layer.name : layer for layer in vgg_model.layers}\n",
        "layer_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8DiIEjue4Zm",
        "outputId": "4a13c832-6347-4967-c8b9-39e4c8b81f3b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'block1_conv1': <keras.layers.convolutional.Conv2D at 0x7ff43c02f990>,\n",
              " 'block1_conv2': <keras.layers.convolutional.Conv2D at 0x7ff43ffb5f50>,\n",
              " 'block1_pool': <keras.layers.pooling.MaxPooling2D at 0x7ff43bf6ee50>,\n",
              " 'block2_conv1': <keras.layers.convolutional.Conv2D at 0x7ff43bf8b250>,\n",
              " 'block2_conv2': <keras.layers.convolutional.Conv2D at 0x7ff43bf1aed0>,\n",
              " 'block2_pool': <keras.layers.pooling.MaxPooling2D at 0x7ff43bfc1150>,\n",
              " 'block3_conv1': <keras.layers.convolutional.Conv2D at 0x7ff43bf20390>,\n",
              " 'block3_conv2': <keras.layers.convolutional.Conv2D at 0x7ff43bf27150>,\n",
              " 'block3_conv3': <keras.layers.convolutional.Conv2D at 0x7ff43bf30310>,\n",
              " 'block3_pool': <keras.layers.pooling.MaxPooling2D at 0x7ff43bf30ed0>,\n",
              " 'block4_conv1': <keras.layers.convolutional.Conv2D at 0x7ff43bf27550>,\n",
              " 'block4_conv2': <keras.layers.convolutional.Conv2D at 0x7ff43bf37c50>,\n",
              " 'block4_conv3': <keras.layers.convolutional.Conv2D at 0x7ff43bf42150>,\n",
              " 'block4_pool': <keras.layers.pooling.MaxPooling2D at 0x7ff43c021b90>,\n",
              " 'block5_conv1': <keras.layers.convolutional.Conv2D at 0x7ff43bf477d0>,\n",
              " 'block5_conv2': <keras.layers.convolutional.Conv2D at 0x7ff43bece850>,\n",
              " 'block5_conv3': <keras.layers.convolutional.Conv2D at 0x7ff43bed4850>,\n",
              " 'block5_pool': <keras.layers.pooling.MaxPooling2D at 0x7ff43bed8910>,\n",
              " 'input_1': <keras.engine.input_layer.InputLayer at 0x7ff444732650>}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "x = layer_dict['block2_conv2'].output\n",
        "\n",
        "x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
        "x = MaxPool2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(10, activation='softmax')(x)\n"
      ],
      "metadata": {
        "id": "phknkq8utNqw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 모델 정의\n",
        "custom_model = Model(inputs=vgg_model.input, outputs=x)\n",
        "custom_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMxhpLxbiS7O",
        "outputId": "3a01f772-ad65-46d5-e91d-4ef33a95906c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 22, 22, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 11, 11, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 7744)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               1982720   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,319,242\n",
            "Trainable params: 2,059,082\n",
            "Non-trainable params: 260,160\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in custom_model.layers[:7]:\n",
        "\tlayer.trainable = False # pre-trained weight를 그대로 사용\n",
        "\n",
        "custom_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "aNvbHtL-iTXF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "MODEL_SAVE_FOLDER = '/content/drive/MyDrive/딥러닝 NLP/models/'\n",
        "model_path = f\"{MODEL_SAVE_FOLDER}mmist-vgg-{{epoch:d}}-{{val_loss:.5f}}-{{val_accuracy:.5f}}.hdf5\"\n",
        "\n",
        "cb_checkpoint = ModelCheckpoint(filepath=model_path, \n",
        "                                monitor='val_accuracy',\n",
        "                                save_weights_only=True,\n",
        "                                verbose=1,\n",
        "                                save_best_only=True)\n",
        "\n",
        "cb_early_stopping= EarlyStopping(monitor='val_accuracy',patience=6) # did not imporoved가 연속으로 6번 나오면 학습 stop"
      ],
      "metadata": {
        "id": "_WHAKWGgocnX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = custom_model.fit(train_images, train_labels, validation_data=(valid_images, valid_labels),\n",
        "                        epochs=100, batch_size=200,\n",
        "                        callbacks=[cb_checkpoint, cb_early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TDDY8hLomIq",
        "outputId": "e918ee43-a220-4540-b528-12e5095ab8ec"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 1.3155 - accuracy: 0.8706\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97141, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-vgg-1-0.10049-0.97141.hdf5\n",
            "300/300 [==============================] - 23s 68ms/step - loss: 1.3155 - accuracy: 0.8706 - val_loss: 0.1005 - val_accuracy: 0.9714\n",
            "Epoch 2/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.9448\n",
            "Epoch 2: val_accuracy improved from 0.97141 to 0.97706, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-vgg-2-0.07620-0.97706.hdf5\n",
            "300/300 [==============================] - 20s 66ms/step - loss: 0.1813 - accuracy: 0.9448 - val_loss: 0.0762 - val_accuracy: 0.9771\n",
            "Epoch 3/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.9494\n",
            "Epoch 3: val_accuracy improved from 0.97706 to 0.97800, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-vgg-3-0.07279-0.97800.hdf5\n",
            "300/300 [==============================] - 20s 65ms/step - loss: 0.1675 - accuracy: 0.9494 - val_loss: 0.0728 - val_accuracy: 0.9780\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9509\n",
            "Epoch 4: val_accuracy improved from 0.97800 to 0.98224, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-vgg-4-0.05875-0.98224.hdf5\n",
            "300/300 [==============================] - 20s 65ms/step - loss: 0.1569 - accuracy: 0.9509 - val_loss: 0.0588 - val_accuracy: 0.9822\n",
            "Epoch 5/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 0.9523\n",
            "Epoch 5: val_accuracy did not improve from 0.98224\n",
            "300/300 [==============================] - 20s 65ms/step - loss: 0.1530 - accuracy: 0.9523 - val_loss: 0.0784 - val_accuracy: 0.9794\n",
            "Epoch 6/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.9530\n",
            "Epoch 6: val_accuracy improved from 0.98224 to 0.98294, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-vgg-6-0.06135-0.98294.hdf5\n",
            "300/300 [==============================] - 20s 66ms/step - loss: 0.1451 - accuracy: 0.9530 - val_loss: 0.0613 - val_accuracy: 0.9829\n",
            "Epoch 7/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1361 - accuracy: 0.9560\n",
            "Epoch 7: val_accuracy did not improve from 0.98294\n",
            "300/300 [==============================] - 20s 65ms/step - loss: 0.1361 - accuracy: 0.9560 - val_loss: 0.0641 - val_accuracy: 0.9798\n",
            "Epoch 8/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9629\n",
            "Epoch 8: val_accuracy did not improve from 0.98294\n",
            "300/300 [==============================] - 20s 65ms/step - loss: 0.1142 - accuracy: 0.9629 - val_loss: 0.0599 - val_accuracy: 0.9828\n",
            "Epoch 9/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9611\n",
            "Epoch 9: val_accuracy did not improve from 0.98294\n",
            "300/300 [==============================] - 20s 65ms/step - loss: 0.1187 - accuracy: 0.9611 - val_loss: 0.0582 - val_accuracy: 0.9827\n",
            "Epoch 10/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.9634\n",
            "Epoch 10: val_accuracy did not improve from 0.98294\n",
            "300/300 [==============================] - 20s 68ms/step - loss: 0.1106 - accuracy: 0.9634 - val_loss: 0.0661 - val_accuracy: 0.9828\n",
            "Epoch 11/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9638\n",
            "Epoch 11: val_accuracy improved from 0.98294 to 0.98506, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-vgg-11-0.05014-0.98506.hdf5\n",
            "300/300 [==============================] - 20s 68ms/step - loss: 0.1083 - accuracy: 0.9638 - val_loss: 0.0501 - val_accuracy: 0.9851\n",
            "Epoch 12/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9635\n",
            "Epoch 12: val_accuracy improved from 0.98506 to 0.98518, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-vgg-12-0.04648-0.98518.hdf5\n",
            "300/300 [==============================] - 20s 66ms/step - loss: 0.1108 - accuracy: 0.9635 - val_loss: 0.0465 - val_accuracy: 0.9852\n",
            "Epoch 13/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9647\n",
            "Epoch 13: val_accuracy did not improve from 0.98518\n",
            "300/300 [==============================] - 20s 65ms/step - loss: 0.1021 - accuracy: 0.9647 - val_loss: 0.0607 - val_accuracy: 0.9827\n",
            "Epoch 14/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9663\n",
            "Epoch 14: val_accuracy improved from 0.98518 to 0.98576, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-vgg-14-0.05541-0.98576.hdf5\n",
            "300/300 [==============================] - 20s 68ms/step - loss: 0.1003 - accuracy: 0.9663 - val_loss: 0.0554 - val_accuracy: 0.9858\n",
            "Epoch 15/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9700\n",
            "Epoch 15: val_accuracy improved from 0.98576 to 0.98800, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-vgg-15-0.04046-0.98800.hdf5\n",
            "300/300 [==============================] - 20s 68ms/step - loss: 0.0891 - accuracy: 0.9700 - val_loss: 0.0405 - val_accuracy: 0.9880\n",
            "Epoch 16/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9684\n",
            "Epoch 16: val_accuracy did not improve from 0.98800\n",
            "300/300 [==============================] - 20s 65ms/step - loss: 0.0948 - accuracy: 0.9684 - val_loss: 0.0531 - val_accuracy: 0.9847\n",
            "Epoch 17/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9657\n",
            "Epoch 17: val_accuracy did not improve from 0.98800\n",
            "300/300 [==============================] - 20s 65ms/step - loss: 0.1008 - accuracy: 0.9657 - val_loss: 0.0514 - val_accuracy: 0.9868\n",
            "Epoch 18/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9672\n",
            "Epoch 18: val_accuracy improved from 0.98800 to 0.98859, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-vgg-18-0.04607-0.98859.hdf5\n",
            "300/300 [==============================] - 20s 67ms/step - loss: 0.0973 - accuracy: 0.9672 - val_loss: 0.0461 - val_accuracy: 0.9886\n",
            "Epoch 19/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.9661\n",
            "Epoch 19: val_accuracy did not improve from 0.98859\n",
            "300/300 [==============================] - 21s 68ms/step - loss: 0.0980 - accuracy: 0.9661 - val_loss: 0.0452 - val_accuracy: 0.9868\n",
            "Epoch 20/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9692\n",
            "Epoch 20: val_accuracy did not improve from 0.98859\n",
            "300/300 [==============================] - 21s 71ms/step - loss: 0.0903 - accuracy: 0.9692 - val_loss: 0.0536 - val_accuracy: 0.9842\n",
            "Epoch 21/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9609\n",
            "Epoch 21: val_accuracy did not improve from 0.98859\n",
            "300/300 [==============================] - 21s 68ms/step - loss: 0.1086 - accuracy: 0.9609 - val_loss: 0.0542 - val_accuracy: 0.9833\n",
            "Epoch 22/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9636\n",
            "Epoch 22: val_accuracy did not improve from 0.98859\n",
            "300/300 [==============================] - 20s 65ms/step - loss: 0.1033 - accuracy: 0.9636 - val_loss: 0.0479 - val_accuracy: 0.9842\n",
            "Epoch 23/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9640\n",
            "Epoch 23: val_accuracy did not improve from 0.98859\n",
            "300/300 [==============================] - 20s 65ms/step - loss: 0.1013 - accuracy: 0.9640 - val_loss: 0.0669 - val_accuracy: 0.9808\n",
            "Epoch 24/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9665\n",
            "Epoch 24: val_accuracy did not improve from 0.98859\n",
            "300/300 [==============================] - 20s 65ms/step - loss: 0.0964 - accuracy: 0.9665 - val_loss: 0.0502 - val_accuracy: 0.9872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la '/content/drive/MyDrive/딥러닝 NLP/models/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzeFsokBu9Wl",
        "outputId": "7c2983f0-5a8e-4988-b611-23c53a3a8c25"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 211738\n",
            "-rw------- 1 root root  404552 Mar  3 02:36 mmist-1-0.06941-0.97847.hdf5\n",
            "-rw------- 1 root root  404552 Mar  3 02:36 mmist-11-0.02098-0.99376.hdf5\n",
            "-rw------- 1 root root  419440 Mar  4 04:58 mmist-1-2.95404-0.21000.hdf5\n",
            "-rw------- 1 root root  419440 Mar  4 06:04 mmist-13-0.02251-0.99341.hdf5\n",
            "-rw------- 1 root root  419440 Mar  4 06:03 mmist-1-4.40705-0.11294.hdf5\n",
            "-rw------- 1 root root  419664 Mar  4 05:33 mmist-1-5.05078-0.11235.hdf5\n",
            "-rw------- 1 root root  404552 Mar  3 02:37 mmist-16-0.02293-0.99412.hdf5\n",
            "-rw------- 1 root root  419440 Mar  4 06:05 mmist-18-0.02067-0.99376.hdf5\n",
            "-rw------- 1 root root  404552 Mar  3 02:37 mmist-20-0.02262-0.99424.hdf5\n",
            "-rw------- 1 root root  404552 Mar  3 02:36 mmist-2-0.04657-0.98506.hdf5\n",
            "-rw------- 1 root root  419440 Mar  4 06:03 mmist-2-0.05850-0.98282.hdf5\n",
            "-rw------- 1 root root  419664 Mar  4 05:33 mmist-2-0.07485-0.97718.hdf5\n",
            "-rw------- 1 root root  419440 Mar  4 04:58 mmist-2-0.12078-0.96376.hdf5\n",
            "-rw------- 1 root root  404552 Mar  3 02:37 mmist-24-0.02115-0.99506.hdf5\n",
            "-rw------- 1 root root  419664 Mar  4 05:33 mmist-3-0.03096-0.99071.hdf5\n",
            "-rw------- 1 root root  404552 Mar  3 02:36 mmist-3-0.04129-0.98753.hdf5\n",
            "-rw------- 1 root root  419440 Mar  4 04:58 mmist-3-0.08658-0.97176.hdf5\n",
            "-rw------- 1 root root  419440 Mar  4 06:03 mmist-4-0.02817-0.99106.hdf5\n",
            "-rw------- 1 root root  419440 Mar  4 04:59 mmist-4-0.03110-0.99082.hdf5\n",
            "-rw------- 1 root root  404552 Mar  3 02:36 mmist-4-0.03284-0.98976.hdf5\n",
            "-rw------- 1 root root  404552 Mar  3 02:36 mmist-5-0.02794-0.99106.hdf5\n",
            "-rw------- 1 root root  419664 Mar  4 05:34 mmist-6-0.02106-0.99329.hdf5\n",
            "-rw------- 1 root root  419440 Mar  4 04:59 mmist-6-0.02188-0.99376.hdf5\n",
            "-rw------- 1 root root  404552 Mar  3 02:36 mmist-6-0.02414-0.99212.hdf5\n",
            "-rw------- 1 root root  419440 Mar  4 06:04 mmist-6-0.02524-0.99118.hdf5\n",
            "-rw------- 1 root root  419664 Mar  4 05:34 mmist-7-0.01984-0.99471.hdf5\n",
            "-rw------- 1 root root  419440 Mar  4 06:04 mmist-7-0.02285-0.99329.hdf5\n",
            "-rw------- 1 root root  419664 Mar  4 05:34 mmist-8-0.01944-0.99482.hdf5\n",
            "-rw------- 1 root root  404552 Mar  3 02:36 mmist-8-0.02252-0.99224.hdf5\n",
            "-rw------- 1 root root 9309328 Mar  4 06:57 mmist-vgg-1-0.10049-0.97141.hdf5\n",
            "-rw------- 1 root root 9309104 Mar  4 06:44 mmist-vgg-10-1.94333-0.30612.hdf5\n",
            "-rw------- 1 root root 9309328 Mar  4 07:00 mmist-vgg-11-0.05014-0.98506.hdf5\n",
            "-rw------- 1 root root 9309104 Mar  4 06:44 mmist-vgg-11-1.91491-0.31247.hdf5\n",
            "-rw------- 1 root root 9309328 Mar  4 07:01 mmist-vgg-12-0.04648-0.98518.hdf5\n",
            "-rw------- 1 root root 9309104 Mar  4 06:41 mmist-vgg-1-2.14676-0.18176.hdf5\n",
            "-rw------- 1 root root 9309328 Mar  4 07:01 mmist-vgg-14-0.05541-0.98576.hdf5\n",
            "-rw------- 1 root root 9309104 Mar  4 06:45 mmist-vgg-14-1.90562-0.31941.hdf5\n",
            "-rw------- 1 root root 9309328 Mar  4 07:02 mmist-vgg-15-0.04046-0.98800.hdf5\n",
            "-rw------- 1 root root 9309104 Mar  4 06:46 mmist-vgg-16-1.89750-0.32200.hdf5\n",
            "-rw------- 1 root root 9309328 Mar  4 07:03 mmist-vgg-18-0.04607-0.98859.hdf5\n",
            "-rw------- 1 root root 9309328 Mar  4 06:57 mmist-vgg-2-0.07620-0.97706.hdf5\n",
            "-rw------- 1 root root 9309104 Mar  4 06:41 mmist-vgg-2-2.08030-0.23047.hdf5\n",
            "-rw------- 1 root root 9309328 Mar  4 06:58 mmist-vgg-3-0.07279-0.97800.hdf5\n",
            "-rw------- 1 root root 9309104 Mar  4 06:41 mmist-vgg-3-2.04972-0.25682.hdf5\n",
            "-rw------- 1 root root 9309328 Mar  4 06:58 mmist-vgg-4-0.05875-0.98224.hdf5\n",
            "-rw------- 1 root root 9309104 Mar  4 06:42 mmist-vgg-4-2.03419-0.26118.hdf5\n",
            "-rw------- 1 root root 9309104 Mar  4 06:42 mmist-vgg-5-2.03387-0.26588.hdf5\n",
            "-rw------- 1 root root 9309328 Mar  4 06:59 mmist-vgg-6-0.06135-0.98294.hdf5\n",
            "-rw------- 1 root root 9309104 Mar  4 06:43 mmist-vgg-7-2.00750-0.27518.hdf5\n",
            "-rw------- 1 root root 9309104 Mar  4 06:43 mmist-vgg-8-1.97807-0.30165.hdf5\n",
            "-rw------- 1 root root 9309104 Mar  4 06:43 mmist-vgg-9-1.95809-0.30306.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_path = \"/content/drive/MyDrive/딥러닝 NLP/models/mmist-vgg-15-0.04046-0.98800.hdf5\"\n",
        "custom_model.load_weights(saved_path)\n",
        "\n",
        "custom_model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-qXxNvEo3PC",
        "outputId": "09cddbaa-aeae-46ea-f1cb-c2ac91049aff"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 1s 17ms/step - loss: 0.0499 - accuracy: 0.9880\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.049854181706905365, 0.9879999756813049]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nJZn4HXVvgth"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}