{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0303_Thurs.ipynb",
      "provenance": [],
      "mount_file_id": "1JyBiuPkWeeYkl2VpdguD3AYrblfvUMbK",
      "authorship_tag": "ABX9TyNXRh8ODGNxMDSwRgVM42rY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoYeoni621/mulcam/blob/master/0303_Thurs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEw_Zj-wUIdJ",
        "outputId": "4d10b4a0-0ad7-4da9-b54c-a4f5bb2714f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((-1, 28, 28, 1))\n",
        "test_images = test_images.reshape((-1, 28, 28, 1))\n",
        "\n",
        "# normalization\n",
        "train_images = train_images/255.\n",
        "test_images = test_images/255.\n",
        "\n",
        "valid_images, test_images, valid_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.15, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functional API 사용"
      ],
      "metadata": {
        "id": "5AMLm9IPAAQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "conv1 = Conv2D(32, (3, 3), activation=tf.nn.relu)(inputs) # 필터의 개수, 필터의 shape, 활성함수\n",
        "pool1 = MaxPool2D((2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation=tf.nn.relu)(pool1)\n",
        "pool2 = MaxPool2D((2, 2))(conv2) \n",
        "\n",
        "conv3 = Conv2D(64, (3, 3), activation=tf.nn.relu)(pool2)\n",
        "flat = Flatten()(conv3) # Dense layer에 넣기 위해 flatten\n",
        "\n",
        "# Dropout 적용\n",
        "dense4 = Dense(64, activation='relu')(flat)\n",
        "drop4 = Dropout(rate=0.2)(dense4) # 정규화 20% 비율로 스킵, 뉴런을 임의로 삭제하면서 학습\n",
        "outputs = Dense(10, activation='softmax')(drop4)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inWhr8W0VjGD",
        "outputId": "f23f3659-eb1e-48f4-c88f-8801135c4942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 576)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                36928     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ModelCheckpoint - 중간에 모델 저장\n",
        "# EarlyStopping - 모델 성능이 더이상 향상되지 않으면 정지"
      ],
      "metadata": {
        "id": "enA62gyrAgeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "MODEL_SAVE_FOLDER = '/content/drive/MyDrive/딥러닝 NLP/models/'\n",
        "model_path = f\"{MODEL_SAVE_FOLDER}mmist-{{epoch:d}}-{{val_loss:.5f}}-{{val_accuracy:.5f}}.hdf5\"\n",
        "\n",
        "cb_checkpoint = ModelCheckpoint(filepath=model_path, \n",
        "                                monitor='val_accuracy',\n",
        "                                save_weights_only=True,\n",
        "                                verbose=1,\n",
        "                                save_best_only=True)\n",
        "cb_early_stopping= EarlyStopping(monitor='val_accuracy',patience=6) # did not imporoved가 연속으로 6번 나오면 학습 stop"
      ],
      "metadata": {
        "id": "BFByxknoWM5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "hist = model.fit(train_images, train_labels, validation_data=(valid_images, valid_labels),\n",
        "                 epochs=100, batch_size=200,\n",
        "                 callbacks=[cb_checkpoint, cb_early_stopping]) # callbacks 는 내가 부르는게 아니고 시스템에서 부르는거(내가 정의해두긴함)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl6f6xDIXxI3",
        "outputId": "6c41149a-f933-446b-ef24-a5946f00ee46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "297/300 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9951\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99224, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-1-0.02966-0.99224.hdf5\n",
            "300/300 [==============================] - 6s 16ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.0297 - val_accuracy: 0.9922\n",
            "Epoch 2/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9964\n",
            "Epoch 2: val_accuracy did not improve from 0.99224\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.0375 - val_accuracy: 0.9906\n",
            "Epoch 3/100\n",
            "299/300 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9963\n",
            "Epoch 3: val_accuracy improved from 0.99224 to 0.99282, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-3-0.02908-0.99282.hdf5\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0291 - val_accuracy: 0.9928\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9971\n",
            "Epoch 4: val_accuracy did not improve from 0.99282\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0366 - val_accuracy: 0.9907\n",
            "Epoch 5/100\n",
            "299/300 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9964\n",
            "Epoch 5: val_accuracy did not improve from 0.99282\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0352 - val_accuracy: 0.9914\n",
            "Epoch 6/100\n",
            "299/300 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9968\n",
            "Epoch 6: val_accuracy did not improve from 0.99282\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.0322 - val_accuracy: 0.9915\n",
            "Epoch 7/100\n",
            "297/300 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9972\n",
            "Epoch 7: val_accuracy did not improve from 0.99282\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.0298 - val_accuracy: 0.9927\n",
            "Epoch 8/100\n",
            "299/300 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9976\n",
            "Epoch 8: val_accuracy did not improve from 0.99282\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0363 - val_accuracy: 0.9925\n",
            "Epoch 9/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9978\n",
            "Epoch 9: val_accuracy did not improve from 0.99282\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0375 - val_accuracy: 0.9927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train_loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='valid_loss')\n",
        "loss_ax.set_xlabel('epochs')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "loss_ax.plot(hist.history['accuracy'], 'b', label='train_accuracy')\n",
        "loss_ax.plot(hist.history['val_accuracy'], 'g', label='valid_accuracy')\n",
        "loss_ax.set_xlabel('epochs')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper roght', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "dZIlazkjauvu",
        "outputId": "04d07929-e224-45ee-da87-547f6ddba5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Unrecognized location 'upper roght'. Falling back on 'best'; valid locations are\n",
            "\tbest\n",
            "\tupper right\n",
            "\tupper left\n",
            "\tlower left\n",
            "\tlower right\n",
            "\tright\n",
            "\tcenter left\n",
            "\tcenter right\n",
            "\tlower center\n",
            "\tupper center\n",
            "\tcenter\n",
            "This will raise an exception in 3.3.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0Duzq7qbZY2",
        "outputId": "db2682b7-af51-41b0-d9be-a7aa1a4fa56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2752\n",
            "drwxr-xr-x 2 root root   4096 Mar  3 01:36 .\n",
            "drwxr-xr-x 1 root root   4096 Mar  3 01:18 ..\n",
            "-rw-r--r-- 1 root root 400264 Mar  3 01:36 mmist-10-0.02655-0.99200.hdf5\n",
            "-rw-r--r-- 1 root root 400264 Mar  3 01:35 mmist-1-0.06942-0.97988.hdf5\n",
            "-rw-r--r-- 1 root root 400264 Mar  3 01:36 mmist-13-0.02808-0.99247.hdf5\n",
            "-rw-r--r-- 1 root root 400264 Mar  3 01:36 mmist-14-0.02939-0.99306.hdf5\n",
            "-rw-r--r-- 1 root root 400264 Mar  3 01:35 mmist-2-0.04619-0.98424.hdf5\n",
            "-rw-r--r-- 1 root root 400264 Mar  3 01:35 mmist-3-0.03493-0.98965.hdf5\n",
            "-rw-r--r-- 1 root root 400264 Mar  3 01:35 mmist-4-0.03209-0.99129.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_path = '/content/drive/MyDrive/딥러닝 NLP/models/mmist-3-0.02908-0.99282.hdf5'\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.load_weights(saved_path)\n",
        "\n",
        "print(f\"Loss, Accuracy {model.evaluate(test_images, test_labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53hXw2fLbvdt",
        "outputId": "eea70116-3b6f-4a92-b429-b595b2bae088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 9s 4ms/step - loss: 0.0378 - accuracy: 0.9913\n",
            "Loss, Accuracy [0.03775019198656082, 0.9913333058357239]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm '/content/drive/MyDrive/딥러닝 NLP/models/'*"
      ],
      "metadata": {
        "id": "tpTcMU14ccC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "\n",
        "class MNISTModel(Model):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.conv1 = Conv2D(32, (3, 3), activation='relu')\n",
        "        self.pool1 = MaxPool2D()\n",
        "        self.conv2 = Conv2D(64, (3, 3), activation='relu')\n",
        "        self.pool2 = MaxPool2D()\n",
        "        self.conv3 = Conv2D(64, (3, 3), activation='relu')\n",
        "        self.flat = Flatten()\n",
        "        self.dense4 = Dense(64, activation='relu')\n",
        "        self.drop = Dropout(0.2)\n",
        "        self.outputs = Dense(10, activation='softmax')\n",
        "\n",
        "    #Forward \n",
        "    def call(self, inputs, training=False):\n",
        "        net = self.conv1(inputs)\n",
        "        net = self.pool1(net)\n",
        "        net = self.conv2(net)\n",
        "        net = self.pool2(net)\n",
        "        net = self.conv3(net)\n",
        "        net = self.flat(net)\n",
        "        net = self.dense4(net)\n",
        "        net = self.drop(net)\n",
        "        net = self.outputs(net)\n",
        "\n",
        "        return net\n",
        "\n",
        "model = MNISTModel()\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "model(inputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQj8-OfslIKf",
        "outputId": "5a5efc93-45f0-420d-cdb1-4fcdaff80c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mnist_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             multiple                  320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  multiple                 0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           multiple                  18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           multiple                  36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           multiple                  0         \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  36928     \n",
            "                                                                 \n",
            " dropout (Dropout)           multiple                  0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "MODEL_SAVE_FOLDER = '/content/drive/MyDrive/딥러닝 NLP/models/'\n",
        "model_path = f\"{MODEL_SAVE_FOLDER}mmist-{{epoch:d}}-{{val_loss:.5f}}-{{val_accuracy:.5f}}.hdf5\"\n",
        "\n",
        "cb_checkpoint = ModelCheckpoint(filepath=model_path, \n",
        "                                monitor='val_accuracy',\n",
        "                                save_weights_only=True,\n",
        "                                verbose=1,\n",
        "                                save_best_only=True)\n",
        "cb_early_stopping= EarlyStopping(monitor='val_accuracy',patience=6)"
      ],
      "metadata": {
        "id": "zKKqyXr6n_Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "hist = model.fit(train_images, train_labels, validation_data=(valid_images, valid_labels),\n",
        "                 epochs=100, batch_size=200,\n",
        "                 callbacks=[cb_checkpoint, cb_early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_5JOzT8opS-",
        "outputId": "f4f75ae4-af0f-402f-ace3-838cc228bc21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "297/300 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8856\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97847, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-1-0.06941-0.97847.hdf5\n",
            "300/300 [==============================] - 4s 8ms/step - loss: 0.3782 - accuracy: 0.8863 - val_loss: 0.0694 - val_accuracy: 0.9785\n",
            "Epoch 2/100\n",
            "295/300 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 0.9705\n",
            "Epoch 2: val_accuracy improved from 0.97847 to 0.98506, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-2-0.04657-0.98506.hdf5\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0978 - accuracy: 0.9707 - val_loss: 0.0466 - val_accuracy: 0.9851\n",
            "Epoch 3/100\n",
            "297/300 [============================>.] - ETA: 0s - loss: 0.0657 - accuracy: 0.9798\n",
            "Epoch 3: val_accuracy improved from 0.98506 to 0.98753, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-3-0.04129-0.98753.hdf5\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0659 - accuracy: 0.9798 - val_loss: 0.0413 - val_accuracy: 0.9875\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9839\n",
            "Epoch 4: val_accuracy improved from 0.98753 to 0.98976, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-4-0.03284-0.98976.hdf5\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.0535 - accuracy: 0.9839 - val_loss: 0.0328 - val_accuracy: 0.9898\n",
            "Epoch 5/100\n",
            "293/300 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9871\n",
            "Epoch 5: val_accuracy improved from 0.98976 to 0.99106, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-5-0.02794-0.99106.hdf5\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.0437 - accuracy: 0.9871 - val_loss: 0.0279 - val_accuracy: 0.9911\n",
            "Epoch 6/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9891\n",
            "Epoch 6: val_accuracy improved from 0.99106 to 0.99212, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-6-0.02414-0.99212.hdf5\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.0365 - accuracy: 0.9891 - val_loss: 0.0241 - val_accuracy: 0.9921\n",
            "Epoch 7/100\n",
            "295/300 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9904\n",
            "Epoch 7: val_accuracy did not improve from 0.99212\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0319 - accuracy: 0.9904 - val_loss: 0.0252 - val_accuracy: 0.9920\n",
            "Epoch 8/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9918\n",
            "Epoch 8: val_accuracy improved from 0.99212 to 0.99224, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-8-0.02252-0.99224.hdf5\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 0.0225 - val_accuracy: 0.9922\n",
            "Epoch 9/100\n",
            "296/300 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9923\n",
            "Epoch 9: val_accuracy did not improve from 0.99224\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0237 - val_accuracy: 0.9921\n",
            "Epoch 10/100\n",
            "296/300 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9937\n",
            "Epoch 10: val_accuracy did not improve from 0.99224\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.0256 - val_accuracy: 0.9918\n",
            "Epoch 11/100\n",
            "296/300 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9935\n",
            "Epoch 11: val_accuracy improved from 0.99224 to 0.99376, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-11-0.02098-0.99376.hdf5\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.0210 - val_accuracy: 0.9938\n",
            "Epoch 12/100\n",
            "296/300 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9944\n",
            "Epoch 12: val_accuracy did not improve from 0.99376\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0213 - val_accuracy: 0.9934\n",
            "Epoch 13/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9949\n",
            "Epoch 13: val_accuracy did not improve from 0.99376\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0202 - val_accuracy: 0.9938\n",
            "Epoch 14/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9956\n",
            "Epoch 14: val_accuracy did not improve from 0.99376\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0218 - val_accuracy: 0.9935\n",
            "Epoch 15/100\n",
            "299/300 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9957\n",
            "Epoch 15: val_accuracy did not improve from 0.99376\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0235 - val_accuracy: 0.9929\n",
            "Epoch 16/100\n",
            "297/300 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9962\n",
            "Epoch 16: val_accuracy improved from 0.99376 to 0.99412, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-16-0.02293-0.99412.hdf5\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.0229 - val_accuracy: 0.9941\n",
            "Epoch 17/100\n",
            "296/300 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9963\n",
            "Epoch 17: val_accuracy did not improve from 0.99412\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0261 - val_accuracy: 0.9926\n",
            "Epoch 18/100\n",
            "297/300 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9970\n",
            "Epoch 18: val_accuracy did not improve from 0.99412\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.0243 - val_accuracy: 0.9933\n",
            "Epoch 19/100\n",
            "296/300 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9969\n",
            "Epoch 19: val_accuracy did not improve from 0.99412\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0219 - val_accuracy: 0.9935\n",
            "Epoch 20/100\n",
            "296/300 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9969\n",
            "Epoch 20: val_accuracy improved from 0.99412 to 0.99424, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-20-0.02262-0.99424.hdf5\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0226 - val_accuracy: 0.9942\n",
            "Epoch 21/100\n",
            "295/300 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9971\n",
            "Epoch 21: val_accuracy did not improve from 0.99424\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0220 - val_accuracy: 0.9939\n",
            "Epoch 22/100\n",
            "295/300 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9974\n",
            "Epoch 22: val_accuracy did not improve from 0.99424\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0233 - val_accuracy: 0.9942\n",
            "Epoch 23/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9976\n",
            "Epoch 23: val_accuracy did not improve from 0.99424\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9941\n",
            "Epoch 24/100\n",
            "296/300 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9975\n",
            "Epoch 24: val_accuracy improved from 0.99424 to 0.99506, saving model to /content/drive/MyDrive/딥러닝 NLP/models/mmist-24-0.02115-0.99506.hdf5\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.0211 - val_accuracy: 0.9951\n",
            "Epoch 25/100\n",
            "298/300 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9977\n",
            "Epoch 25: val_accuracy did not improve from 0.99506\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0216 - val_accuracy: 0.9947\n",
            "Epoch 26/100\n",
            "296/300 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9980\n",
            "Epoch 26: val_accuracy did not improve from 0.99506\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0288 - val_accuracy: 0.9932\n",
            "Epoch 27/100\n",
            "297/300 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9984\n",
            "Epoch 27: val_accuracy did not improve from 0.99506\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0342 - val_accuracy: 0.9938\n",
            "Epoch 28/100\n",
            "294/300 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9982\n",
            "Epoch 28: val_accuracy did not improve from 0.99506\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0305 - val_accuracy: 0.9933\n",
            "Epoch 29/100\n",
            "296/300 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9979\n",
            "Epoch 29: val_accuracy did not improve from 0.99506\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0329 - val_accuracy: 0.9933\n",
            "Epoch 30/100\n",
            "297/300 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9979\n",
            "Epoch 30: val_accuracy did not improve from 0.99506\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0275 - val_accuracy: 0.9936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_path = '/content/drive/MyDrive/딥러닝 NLP/models/mmist-20-0.02262-0.99424.hdf5'\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.load_weights(saved_path)\n",
        "\n",
        "print(f\"Loss, Accuracy {model.evaluate(test_images, test_labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHKV5qnBotgf",
        "outputId": "f7f8922c-8231-44ed-e50a-88b91894e87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 9s 6ms/step - loss: 0.0126 - accuracy: 0.9973\n",
            "Loss, Accuracy [0.01257546991109848, 0.9973333477973938]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(test_images)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRyrcbeopYDv",
        "outputId": "edbfd598-80fb-43eb-ebcf-c2fb67c99c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1500, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "output[0] # softmax를 거친 값\n",
        "np.argmax(output[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uNRMFW3CViC",
        "outputId": "94677403-4891-4175-f1f2-61f82f72a696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8PmkAPTCYLx",
        "outputId": "390641ec-fa6d-42c7-9d06-a0461a775ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l7U6eMvmCoGg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}